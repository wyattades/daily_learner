{{extend 'layout.html'}}


<h1 class="is-size-1">About</h1>

<div class="content">

    <hr/>

    <h3>Scikit Model</h3>
    <div class="columns" >
        <div class="column">
            <p>
                This model uses a standard liner regression technique provided buy the popular python
                scientific data analysis package <a href="http://scikit-learn.org/stable/index.html">scikit-learn</a>
                The underlying algorithm for this linear regression is the Ordinary Least Squares, or OSL.
                The OSL algorithm works by picking different coefficient for a each of the input variables in order
                to minimize the sum of the squared errors.  The error in this case can be calculated as the distance
                between the predicted output variable and the actual output variable. Once the optimum coefficients are found,
                prediction can be preformed by simply plugging in the input values into there respective variables and solving
                for the output variable. This method in an abstract scene is finding the “best” solution to an over constrained
                set of linear equations. With each of the linear equations being defined one line of you input data.
            </p>
        </div>
        <div class="column">
            <figure>
                <img src="daily_learner/static/images/linear_regress.jpg" width="500" alt="">
                <figcaption>
                    Figure 1: Example of basic linear regression using scikit-learn <br>
                </figcaption>
            </figure>
        </div>
    </div>

    <h5>When to use:</h5>
    <ul>
        <li>Smaller data sets (0-50)</li>
        <li>A linear/semi-linear relationship</li>
        <li>Fast training/prediction</li>
        <li>Simplistic model for regression</li>
    </ul>

    <br/>
    <hr/>

    <h3>Linear Model</h3>
    <div class="columns">
        <div class="column">
            <p>
                The Linear model uses a <a href="https://keras.io/">Keras</a>  Sequential model at its core. It is a 3
                layer neural network with 20 nodes at each layer, each layer being fully connected with the
                last layer containing one output node. Every layer’s activation function is linear, meaning
                that the output node will always be some linear combination of the input nodes, making this
                model effectively the same as the scikit model except for the method in which the coefficients
                are found. In this model, the coefficients are found by passing the input values through the
                previously described neural network. For each connection between nodes there is a weight value
                what is applied to the input nodes current value, which results the new nodes value. These weights
                are fine tuned using the adam optimization technique which is an of shoot of
                <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic Gradient Decent</a>.
                The cost function we used for this model is the mean squared error cost function which just averages the squares of the errors
                for the models prediction. With each iteration of data through the model the weights between each
                of the node connections are tweaked to minimize the mean squared error. This model has a slightly
                more difficult method of prediction because the weights are not know like in the scikit model.
                Therefore a prediction can only be generated by passing the input values through the model.
            </p>
        </div>
        <div class="column">
            <figure>
                <img src="daily_learner/static/images/nn.jpg" width="500px">
                <figcaption>
                    Figure 2: Example of symple keras neural network with 2 hidden layers <br>
                </figcaption>
            </figure>
        </div>
    </div>

    <h5>When to use:</h5>
    <ul>
        <li>Small to medium data sets (0-2000)</li>
        <li>A linear/semi-linear relationship</li>
        <li>Slower training/testing speed is not a problem</li>
        <li>Verification for Scikit Model</li>
    </ul>

    <br/>
    <hr/>

    <h3>Blackbox Model</h3>
    <div class="columns">
        <div class="column">
            <p>
                The Blackbox model contains a 2 hidden layers consisting each of containing 20 fully connected nodes.
                This model is the exact same concept as the Linear model except for the activation functions.
                Different Activation functions are applied to the connections between layers.
                This allows a non-linear relationship to be discovered between each of the input nodes.
                The activation functions allow for complex relationships to be determined between each of the
                variables. Though the creators of the network will not know explicitly what they are, they will
                appear in the results. This is why the model is refered to as the Blackbox model. The first activation
                function is a rectifier(ReLU) function and the second activation function is a sigmoid function. This
                technique is a popular modern approach to generic regression problems. More complex networks can
                be generated using different activation functions, and more/larger hidden layers.
            </p>
        </div>
        <div class="column">
            <figure>
                <img src="daily_learner/static/images/activation_fun.jpg" width="500">
                <figcaption>
                    Figure 3: The two activation functions used for this neural network
                </figcaption>
            </figure>
        </div>
    </div>

    <h5>When to use:</h5>
    <ul>
        <li>Large data sets (>2000)</li>
        <li>Complex relationships between data</li>
        <li>Slower training/testing speed is not a problem</li>
    </ul>

    <br/>
    <hr/>

    <div class="image_sources">
        <h6 style="color: #BEBEBE">Image sources:</h6>
        <small style="color: #BEBEBE">Figure 1:
            <a href="http://bigdata-madesimple.com/how-to-run-linear-regression-in-python-scikit-learn/">
                http://bigdata-madesimple.com/
            </a>
        </small>
        <br>
        <small style="color: #BEBEBE">Figure 2:
            <a href="http://blog.christianperone.com/2015/08/convolutional-neural-networks-and-feature-extraction-with-python/">
                http://blog.christianperone.com/
            </a>
        </small>
        <br>
        <small style="color: #BEBEBE">Figure 3:
            <a href="https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6">
                https://towardsdatascience.com/
            </a>
        </small>

    </div>
</div>
